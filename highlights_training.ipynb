from multiprocessing import Pool, Manager


#1. Use Selenium to do searches
#2. Use OpenAI API to select best video out of top 5
#3. Get the transcript or audio from url we'll try transcript first
#3. Use Whisper API to transcribe (bc I think my bank acct is linked)
#4. Tokenize transcripts & highlights (probably just split on space) & create the label arrays
#5. Create train/test/val splits (80/10/10)
#6. Use Google cloud to train (biggest GPU)
#7. Then I need to evaluate too, which will be hard
import selenium
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from urllib.parse import urlparse, parse_qs
from youtube_transcript_api import YouTubeTranscriptApi
from dotenv import load_dotenv
import openai
import json
import random
from rapidfuzz import process, fuzz
import os, time
import cProfile



load_dotenv()

OPENAI_API_KEY="PLACEHOLDER"
openai.api_key = OPENAI_API_KEY
#Function uses Selenium to pull the video resources from youtube
def get_youtube_results(n, query):
    t1 = time.time()
    #print("Getting Youtube results")
    # Configure Selenium for headless operation

    #Error could be up heere
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    retries = 3
    # Initialize the WebDriver
    driver = webdriver.Chrome(options=options)
    driver.set_page_load_timeout(99999)  # Increase page load timeout
    driver.set_script_timeout(99999)
    for att in range(retries):

        try:
            # Search YouTube with the query
            search_url = f"https://www.youtube.com/results?search_query={query.replace(' ', '+')}"
            driver.get(search_url)
            time.sleep(3)  # Wait for the page to load

            # Locate the video elements


            video_elements = WebDriverWait(driver, 10).until(
                EC.presence_of_all_elements_located((By.XPATH, '//ytd-video-renderer'))  # Replace with the actual locator
            )
            video_elements = video_elements[:n]

            # Extract information
            results = []
            for video in video_elements:

                # Extracting data from video elements
                title_element = video.find_element(By.XPATH, './/a[@id="video-title"]')
                title = title_element.text
                url = title_element.get_attribute('href')


                channel_elem = video.find_element(By.ID, 'channel-name')
                container = channel_elem.find_element(By.ID, 'text')
                # channel_a_tag = WebDriverWait(driver,10).until(
                #     EC.visibility_of_element_located((By.XPATH, './/a'))
                # )
                channel_a_tag= container.find_element(By.TAG_NAME, 'a')
                channel_name = channel_a_tag.get_attribute('textContent')


                # duration_element = video.find_element(By.XPATH, './/ytd-thumbnail-overlay-time-status-renderer/span')
                # duration = duration_element.text.strip()

                # Append result
                results.append({
                    'title': title,
                    'url': url,
                    'channel_name': channel_name,
                })
            return results

        except Exception as e:
            # Handle potential exceptions gracefully
            print(f"Error extracting information from a video: {e}")
            t2 = time.time()
            #print("Done getting youtube video", t2-t1)

        finally:
        # Close the browser
            driver.quit()

'''

we can add some efficiencies to these various functions and maybe use something else to pick best video

'''

#FN uses OpenAI API to select best video from list
def select_best_video(video_choices:list):
    #print("Selecting best video")
    videoMssg = ""

    for i in range(len(video_choices)):
        videoMssg += f'{i}: {video_choices[i]}\n'


    systemPrompt = 'You are a selector of football youtube highlights videos and can only respond with numerical numbers like 1,2,3...etc'
    footballMessage = f"Select the best football highlights youtube video from the following list, only return the number\n {videoMssg}"


    # Define the conversation
    messages = [
        {"role": "system", "content": systemPrompt},
        {"role": "user", "content": footballMessage}
    ]
    model = 'gpt-3.5-turbo'
    # Make the API call
    response = openai.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=100,
        temperature=0.3
    )

    # Extract and return the model's reply
    choice = response.choices[0].message.content
    try:
        best =  int(choice)
        #print("Done selecting video")
        return best
    except ValueError:
        #print("Failed to select video")
        return None




def fuzzyMatch(query, bigString, start):

    qLen= len(query)
    bestScore = 0
    startIndex = start
    for i in range(start, len(bigString) - qLen):
        segment_string = bigString[i:i+qLen]
        score = fuzz.ratio(query, segment_string)
        if score > bestScore:
            bestScore = score
            startIndex = i

    return startIndex, qLen

def store_transcript(transcript, filename):
    with open(filename, 'w') as f:
        json.dump(transcript, f, indent=4)


def labelTranscript(original_transcript:str, highlight_transcript:list):
    original_transcript = original_transcript.lower()
    tokens = original_transcript.split()
    labels = ['o'] * len(tokens)
    currHighlight = ""
    lastLocation = 0
    for elem in highlight_transcript:
        text = elem['text'].lower()
        #exclude applause for now, in future we will include it with multimodal data
        #okay lets go
        word_list = text.split()

        if len(word_list) == 1:
            if word_list[0].strip() != '[Applause]':
                currHighlight += text
            continue

        if currHighlight:
            currHighlight += text
            start, qLen = fuzzyMatch(currHighlight, tokens, lastLocation)
            currHighlight = ""
        else:
            start, qLen = fuzzyMatch(word_list, tokens, lastLocation)
        lastLocation = start + qLen
        #search for position in transcript
        for j in range(start, start + qLen):
            labels[j] = 'H'

    return labels

    #tokens, labels


#now we have highlights, OG transcripts, we just need to compare and add the labels


def putItTogether(sorted_keys, video_queries, ):
    pass



#def main():
#Then we move this to azure and start running the full pipeline in the cloud,
#Resolve issues, probably have to install a number of packages
#Then we train & evaluate using the hugging face code
def process_query(args):
        query, key, transcriptStructure = args[0], args[1], args[2]
        print(f"processing query {query} | key {key}")
        #count[0] += 1
        #this is kind of async
        videos = get_youtube_results(1, query)
        #this is async
        best_video = select_best_video(videos)
        #print("Best Video",best_video)
        if best_video == None or best_video > len(videos):
            return None
        selected_video = videos[best_video-1]
        #this seems to be slow
        highlights = getHighlightTranscript(selected_video['url'])
        currKey = transcriptStructure.get(key, {})
        currKey['highlights'] = highlights
        transcriptStructure[key] = currKey
        #print(transcriptStructure[key]['highlights'])
        print(f"finished query {query} | key {key}", ('highlights' in transcriptStructure[key]))

def preprocessKeys(keys):
    #with open(fname) as jsonF:
    i = 0
        #data = json.load(jsonF)

    keys = list(keys)
    while i < len(keys):
        key = keys[i]
        if key[-6] == '-':
            keys.pop(i)
        i+=1

    return keys

#Function takes the json file and returns the video queries and keys of the different matches
def pullJSON(fname):

    with open(fname) as jsonF:

        #jsonloads
        #what do i do first...

        i = 0
        data = json.load(jsonF)

        keys = data.keys()
        key_list = preprocessKeys(keys)
        print("KEYLEN", len(key_list))
        #store_transcript(key_list, 'key_list.txt')
        #print(data['2018-tennessee_titans-tampa_bay_buccaneers.txt'])

        e = jsonF.readline()
        transcriptStructure = {}

        sorted_keys = sorted(key_list, key= lambda x: int(x.split('-')[0]))

        sorted_video_queries = []

        for key in sorted_keys:
            transcript, teams = data[key]['transcript'], data[key]['teams']

            transcriptStructure[key] = {'transcript': transcript, 'teams': teams}
            #cut off txt
            stringTake = key[:-4]
            strList = stringTake.split('-')
            team1 = " ".join(strList[1].split('_'))
            team2 = " ".join(strList[2].split('_'))
            query = strList[0] + ' ' +team1 +' versus ' + team2 + ' highlights'
            sorted_video_queries.append(query)


        return sorted_keys, sorted_video_queries, transcriptStructure












